---
title: "Exercise Analysis"
author: "Rene Keller"
date: "5/21/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This paper describes the analysis of the Exercise data. Two datasets were downloaded. First, the trainng set:
<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv>

and then the test Set

<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>

## Loading Data

First we load the data and the different librarires (including caret).
```{r DataLoad}
trainDS<-read.csv("pml-training.csv")
testDS<-read.csv("pml-testing.csv")
library(caret)
library(randomForest)
```


## Data Cleaning

First we notice that there are a lot of columns that have all NAs as well as some columns that only show data for the beginning of the frame. Examining the test dataset, these are all NAs in the test dataset, hence they are removed.
Finally, we create a Training and Test dataset (with a 70:30 split) from the original Test Dataset

```{r DataClean}


testclean_final<-testDS[,c(8:11,46:49,84:86,102,122:124,140,160)]

traincleanint<-trainDS[,c(8:11,46:49,84:86,102,122:124,140,160)]
inTrain<-createDataPartition(y=traincleanint$classe,p=0.7,list=FALSE)

trainClean<-traincleanint[inTrain,]
testClean<-traincleanint[-inTrain,]

```



## Random Tree

The first model that i fit will be a random tree. See below the resulting tree and its accuracy.

```{r randomTree}
## create the model
modelTree<-train(classe~.,method="rpart", data=trainClean)
## Plot the Tree
plot(modelTree$finalModel,uniform=TRUE,main="Classification Tree")
text(modelTree$finalModel,use.n=TRUE,all=TRUE,cex=0.8)
##Create the prediction
predictTree<-predict(modelTree,testClean)
## Sumamry table
table(predictTree,testClean$classe)
##Calculate accuracy
accuracyTree<-sum(predictTree==testClean$classe)/length(testClean$classe)

```
One can see that the accuracy of `r accuracyTree` is pretty low and the model does not do a great job predicting the test dataset.

## Random Forests

Based on the disappointing results from the Random tree model, we now fit a random foorest model to the data.

```{r randomForest}
## create the model
modelForest<-randomForest(classe~., data=trainClean)
## Plot the Tree
## plot(modelTree$finalModel,uniform=TRUE,main="Classification Tree")
##Create the prediction
predictForest<-predict(modelForest,testClean)
## Sumamry table
table(predictForest,testClean$classe)
##Calculate accuracy
accuracyForest<-sum(predictForest==testClean$classe)/length(testClean$classe)

```
One can see that the accuracy of `r accuracyForest` is much better in predicting the testing Dataset.

## Predicting the Final Test
We use the forest model from the previous sesction to now predict the test dataset. We also print out the results

```{r FINAL}
##Create the prediction
predictForestFINAL<-predict(modelForest,testclean_final)

predictForestFINAL

```